{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from options  import stage2_opts\n",
    "from utils    import logger, recorders\n",
    "from datasets import custom_data_loader\n",
    "from models   import custom_model, solver_utils, model_utils\n",
    "\n",
    "import train_stage2 as train_utils\n",
    "import test_stage2 as test_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--save_split'], dest='save_split', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('--dataset',     default='UPS_PRPS_Dataset')\n",
    "parser.add_argument('--data_dir',    default='data/datasets/PRPS_Dataset')\n",
    "parser.add_argument('--data_dir2',   default='data/datasets/PS_Sculpture_Dataset')\n",
    "parser.add_argument('--concat_data', default=False, action='store_false')\n",
    "parser.add_argument('--l_suffix',    default='_mtrl.txt')\n",
    "\n",
    "#### Training Data and Preprocessing Arguments ####\n",
    "parser.add_argument('--rescale',     default=True,  action='store_false')\n",
    "parser.add_argument('--rand_sc',     default=True,  action='store_false')\n",
    "parser.add_argument('--scale_h',     default=128,   type=int)\n",
    "parser.add_argument('--scale_w',     default=128,   type=int)\n",
    "parser.add_argument('--crop',        default=True,  action='store_false')\n",
    "parser.add_argument('--crop_h',      default=128,   type=int)\n",
    "parser.add_argument('--crop_w',      default=128,   type=int)\n",
    "parser.add_argument('--test_h',      default=128,   type=int)\n",
    "parser.add_argument('--test_w',      default=128,   type=int)\n",
    "parser.add_argument('--test_resc',   default=True,  action='store_false')\n",
    "parser.add_argument('--int_aug',     default=False,  action='store_false')\n",
    "parser.add_argument('--noise_aug',   default=False,  action='store_false')\n",
    "parser.add_argument('--noise',       default=0.05,  type=float)\n",
    "parser.add_argument('--color_aug',   default=False,  action='store_false')\n",
    "parser.add_argument('--color_ratio', default=3,     type=float)\n",
    "parser.add_argument('--normalize',   default=False, action='store_true')\n",
    "\n",
    "#### Device Arguments ####\n",
    "parser.add_argument('--cuda',        default=True,  action='store_false')\n",
    "parser.add_argument('--multi_gpu',   default=False, action='store_true')\n",
    "parser.add_argument('--time_sync',   default=False, action='store_true')\n",
    "parser.add_argument('--workers',     default=4,     type=int)\n",
    "parser.add_argument('--seed',        default=0,     type=int)\n",
    "\n",
    "#### Stage 1 Model Arguments ####\n",
    "parser.add_argument('--dirs_cls',    default=36,    type=int)\n",
    "parser.add_argument('--ints_cls',    default=20,    type=int)\n",
    "parser.add_argument('--dir_int',     default=False, action='store_true')\n",
    "parser.add_argument('--model',       default='LCNet')\n",
    "parser.add_argument('--fuse_type',   default='max')\n",
    "parser.add_argument('--in_img_num',  default=10,    type=int)\n",
    "parser.add_argument('--s1_est_n',    default=False, action='store_true')\n",
    "parser.add_argument('--s1_est_d',    default=True,  action='store_false')\n",
    "parser.add_argument('--s1_est_i',    default=True,  action='store_false')\n",
    "parser.add_argument('--in_light',    default=False, action='store_true')\n",
    "parser.add_argument('--in_mask',     default=True,  action='store_false')\n",
    "parser.add_argument('--use_BN',      default=False, action='store_true')\n",
    "parser.add_argument('--resume',      default=None)\n",
    "parser.add_argument('--retrain',     default='data/logdir/UPS_Synth_Dataset/CVPR2019/10_images/checkp_20.pth.tar')\n",
    "parser.add_argument('--save_intv',   default=10,     type=int)\n",
    "\n",
    "#### Stage 2 Model Arguments ####\n",
    "parser.add_argument('--stage2',      default=True, action='store_true')\n",
    "parser.add_argument('--model_s2',    default='NENet')\n",
    "parser.add_argument('--retrain_s2',  default=None)\n",
    "parser.add_argument('--s2_est_n',    default=True,  action='store_false')\n",
    "parser.add_argument('--s2_est_i',    default=False, action='store_true')\n",
    "parser.add_argument('--s2_est_d',    default=False, action='store_true')\n",
    "parser.add_argument('--s2_in_light', default=True,  action='store_false')\n",
    "\n",
    "#### Displaying Arguments ####\n",
    "parser.add_argument('--train_disp',    default=20,  type=int)\n",
    "parser.add_argument('--train_save',    default=200, type=int)\n",
    "parser.add_argument('--val_intv',      default=1,   type=int)\n",
    "parser.add_argument('--val_disp',      default=1,   type=int)\n",
    "parser.add_argument('--val_save',      default=1,   type=int)\n",
    "parser.add_argument('--max_train_iter',default=-1,  type=int)\n",
    "parser.add_argument('--max_val_iter',  default=-1,  type=int)\n",
    "parser.add_argument('--max_test_iter', default=-1,  type=int)\n",
    "parser.add_argument('--train_save_n',  default=4,   type=int)\n",
    "parser.add_argument('--test_save_n',   default=4,   type=int)\n",
    "\n",
    "#### Log Arguments ####\n",
    "parser.add_argument('--save_root',  default='data/logdir/')\n",
    "parser.add_argument('--item',       default='CVPR2019')\n",
    "parser.add_argument('--suffix',     default=None)\n",
    "parser.add_argument('--debug',      default=False, action='store_true')\n",
    "parser.add_argument('--make_dir',   default=True,  action='store_false')\n",
    "parser.add_argument('--save_split', default=False, action='store_true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--rec_w'], dest='rec_w', nargs=None, const=None, default=60, type=<class 'float'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('--solver',      default='adam', help='adam|sgd')\n",
    "parser.add_argument('--milestones',  default=[2, 4, 6, 8, 10], nargs='+', type=int)\n",
    "parser.add_argument('--start_epoch', default=1,      type=int)\n",
    "parser.add_argument('--epochs',      default=200,     type=int)\n",
    "parser.add_argument('--batch',       default=8,     type=int)\n",
    "parser.add_argument('--val_batch',   default=1,      type=int)\n",
    "parser.add_argument('--init_lr',     default=0.0005, type=float)\n",
    "parser.add_argument('--lr_decay',    default=0.5,    type=float)\n",
    "parser.add_argument('--beta_1',      default=0.9,    type=float, help='adam')\n",
    "parser.add_argument('--beta_2',      default=0.999,  type=float, help='adam')\n",
    "parser.add_argument('--momentum',    default=0.9,    type=float, help='sgd')\n",
    "parser.add_argument('--w_decay',     default=4e-4,   type=float)\n",
    "\n",
    "#### Loss Arguments ####\n",
    "parser.add_argument('--normal_loss', default='cos',  help='cos|mse')\n",
    "parser.add_argument('--normal_w',    default=1,      type=float)\n",
    "parser.add_argument('--dir_loss',    default='mse',  help='cos|mse')\n",
    "parser.add_argument('--dir_w',       default=1,      type=float)\n",
    "parser.add_argument('--ints_loss',   default='mse',  help='mse')\n",
    "parser.add_argument('--ints_w',      default=1,      type=float)\n",
    "parser.add_argument('--rec_loss', default='L1',  help='L1|L2')\n",
    "parser.add_argument('--rec_w',    default=60,      type=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch=8, beta_1=0.9, beta_2=0.999, color_aug=False, color_ratio=3, concat_data=False, crop=True, crop_h=128, crop_w=128, cuda=True, data_dir='data/datasets/PRPS_Dataset', data_dir2='data/datasets/PS_Sculpture_Dataset', dataset='UPS_PRPS_Dataset', debug=False, dir_int=False, dir_loss='mse', dir_w=1, dirs_cls=36, epochs=200, fuse_type='max', in_img_num=10, in_light=False, in_mask=True, init_lr=0.0005, int_aug=False, ints_cls=20, ints_loss='mse', ints_w=1, item='CVPR2019', l_suffix='_mtrl.txt', lr_decay=0.5, make_dir=True, max_test_iter=-1, max_train_iter=-1, max_val_iter=-1, milestones=[2, 4, 6, 8, 10], model='LCNet', model_s2='NENet', momentum=0.9, multi_gpu=False, noise=0.05, noise_aug=False, normal_loss='cos', normal_w=1, normalize=False, rand_sc=True, rec_loss='L1', rec_w=60, rescale=True, resume=None, retrain='data/logdir/UPS_Synth_Dataset/CVPR2019/10_images/checkp_20.pth.tar', retrain_s2=None, s1_est_d=True, s1_est_i=True, s1_est_n=False, s2_est_d=False, s2_est_i=False, s2_est_n=True, s2_in_light=True, save_intv=10, save_root='data/logdir/', save_split=False, scale_h=128, scale_w=128, seed=0, solver='adam', stage2=True, start_epoch=1, suffix=None, test_h=128, test_resc=True, test_save_n=4, test_w=128, time_sync=False, train_disp=20, train_save=200, train_save_n=4, use_BN=False, val_batch=1, val_disp=1, val_intv=1, val_save=1, w_decay=0.0004, workers=4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(args):\n",
    "    print('Creating Model %s' % (args.model))\n",
    "    in_c = 4\n",
    "    other = {\n",
    "            'img_num':  args.in_img_num, \n",
    "            'test_h':   args.test_h,   'test_w':   args.test_w,\n",
    "            'in_mask':  args.in_mask,  'in_light': args.in_light, \n",
    "            'dirs_cls': args.dirs_cls, 'ints_cls': args.ints_cls,\n",
    "            's1_est_d': args.s1_est_d, 's1_est_i': args.s1_est_i, 's1_est_n': args.s1_est_n, \n",
    "            }\n",
    "    models = __import__('models.' + args.model)\n",
    "    model_file = getattr(models, args.model)\n",
    "    model = getattr(model_file, args.model)(args.fuse_type, args.use_BN, in_c, other)\n",
    "\n",
    "    if args.cuda: model = model.cuda()\n",
    "\n",
    "    if args.retrain: \n",
    "        model_utils.loadCheckpoint(args.retrain, model, cuda=args.cuda)\n",
    "\n",
    "    if args.resume:\n",
    "        model_utils.loadCheckpoint(args.resume, model, cuda=args.cuda)\n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model LCNet\n",
      "LCNet(\n",
      "  (featExtractor): FeatExtractor(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv4): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv6): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv4): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (dir_x_est): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (dir_y_est): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = buildModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModelStage2(args):\n",
    "    print('Creating Stage2 Model %s' % (args.model_s2))\n",
    "    # in_c = 6 if args.s2_in_light else 3\n",
    "    in_c = 4\n",
    "    other = {\n",
    "            'img_num':  args.in_img_num,\n",
    "            'in_mask':  args.in_mask,  'in_light': args.in_light, \n",
    "            'dirs_cls': args.dirs_cls, 'ints_cls': args.ints_cls,\n",
    "            }\n",
    "    models = __import__('models.' + args.model_s2)\n",
    "    model_file = getattr(models, args.model_s2)\n",
    "    model = getattr(model_file, args.model_s2)(args.fuse_type, args.use_BN, in_c, other)\n",
    "\n",
    "    if args.cuda: model = model.cuda()\n",
    "\n",
    "    if args.retrain_s2: \n",
    "        model_utils.loadCheckpoint(args.retrain_s2, model, cuda=args.cuda)\n",
    "\n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Stage2 Model NENet\n",
      "NENet(\n",
      "  (generator): Generator(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (7): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (10): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): ResidualBlock(\n",
      "        (main): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResidualBlock(\n",
      "        (main): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResidualBlock(\n",
      "        (main): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResidualBlock(\n",
      "        (main): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ResidualBlock(\n",
      "        (main): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): ResidualBlock(\n",
      "        (main): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (22): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (23): ReLU(inplace=True)\n",
      "      (24): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (25): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): Conv2d(16, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (28): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (regressor): Regressor(\n",
      "    (conv1): Conv2d(2, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (denseblock1_1): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): Dropout2d(p=0.2, inplace=False)\n",
      "    )\n",
      "    (denseblock1_2): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): Dropout2d(p=0.2, inplace=False)\n",
      "    )\n",
      "    (transition): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Dropout2d(p=0.2, inplace=False)\n",
      "      (3): AvgPool2d(kernel_size=4, stride=2, padding=1)\n",
      "    )\n",
      "    (denseblock2_1): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): Dropout2d(p=0.2, inplace=False)\n",
      "    )\n",
      "    (denseblock2_2): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): Dropout2d(p=0.2, inplace=False)\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(80, 160, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): InstanceNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(160, 320, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (4): InstanceNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(320, 640, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (7): InstanceNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "    )\n",
      "    (pooling): AvgPool2d(kernel_size=4, stride=2, padding=1)\n",
      "    (conv2): Conv2d(640, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_s2 = buildModelStage2(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model, model_s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configOptimizer(args, model):\n",
    "    records = None\n",
    "    optimizer = getOptimizer(args, model.parameters())\n",
    "    if args.resume:\n",
    "        records, start_epoch = loadRecords(args.resume, model, optimizer)\n",
    "        args.start_epoch = start_epoch\n",
    "    scheduler = getLrScheduler(args, optimizer)\n",
    "    return optimizer, scheduler, records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptimizer(args, params):\n",
    "#     args.log.printWrite('=> Using %s solver for optimization' % (args.solver))\n",
    "    if args.solver == 'adam':\n",
    "        optimizer = torch.optim.Adam(params, args.init_lr, betas=(args.beta_1, args.beta_2))\n",
    "    elif args.solver == 'sgd':\n",
    "        optimizer = torch.optim.SGD(params, args.init_lr, momentum=args.momentum)\n",
    "    else:\n",
    "        raise Exception(\"=> Unknown Optimizer %s\" % (args.solver))\n",
    "    return optimizer\n",
    "\n",
    "def getLrScheduler(args, optimizer):\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "            milestones=args.milestones, gamma=args.lr_decay, last_epoch=args.start_epoch-2)\n",
    "    return scheduler\n",
    "\n",
    "def loadRecords(path, model, optimizer):\n",
    "    records = None\n",
    "    if os.path.isfile(path):\n",
    "        records = torch.load(path[:-8] + '_rec' + path[-8:])\n",
    "        optimizer.load_state_dict(records['optimizer'])\n",
    "        start_epoch = records['epoch'] + 1\n",
    "        records = records['records']\n",
    "        print(\"=> loaded Records\")\n",
    "    else:\n",
    "        raise Exception(\"=> no checkpoint found at '{}'\".format(path))\n",
    "    return records, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, scheduler, records = configOptimizer(args, model_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage2Crit(object): # Second stage\n",
    "    def __init__(self, args):\n",
    "        self.s2_est_n = args.s2_est_n \n",
    "        self.s2_est_d = args.s2_est_d\n",
    "        self.s2_est_i = args.s2_est_i\n",
    "        self.setupLightCrit(args)\n",
    "        if self.s2_est_n:\n",
    "            self.setupNormalCrit(args)\n",
    "        self.setupRecCrit(args)\n",
    "\n",
    "    def setupRecCrit(self, args):\n",
    "#         args.log.printWrite('=> Using reconstruction criterion')\n",
    "        if args.rec_loss == 'L1':\n",
    "            self.rec_crit = torch.nn.L1Loss()\n",
    "        elif args.rec_loss == 'L2':\n",
    "            self.rec_crit = torch.nn.MSELoss()\n",
    "        self.rec_w = args.rec_w\n",
    "\n",
    "    def setupLightCrit(self, args):\n",
    "#         args.log.printWrite('=> Using light criterion')\n",
    "        if self.s2_est_d:\n",
    "            self.dir_w = args.dir_w\n",
    "            self.dirs_crit = torch.nn.CosineEmbeddingLoss()\n",
    "            if args.cuda: self.dirs_crit = self.dirs_crit.cuda()\n",
    "        if self.s2_est_i:\n",
    "            self.ints_w = args.ints_w\n",
    "            self.ints_crit = torch.nn.MSELoss()\n",
    "            if args.cuda: self.ints_crit = self.ints_crit.cuda()\n",
    "\n",
    "    def setupNormalCrit(self, args):\n",
    "#         args.log.printWrite('=> Using {} for criterion normal'.format(args.normal_loss))\n",
    "        self.normal_w = args.normal_w\n",
    "        if args.normal_loss == 'mse':\n",
    "            self.n_crit = torch.nn.MSELoss()\n",
    "        elif args.normal_loss == 'cos':\n",
    "            self.n_crit = torch.nn.CosineEmbeddingLoss()\n",
    "        else:\n",
    "            raise Exception(\"=> Unknown Criterion '{}'\".format(args.normal_loss))\n",
    "        if args.cuda:\n",
    "            self.n_crit = self.n_crit.cuda()\n",
    "\n",
    "    def forward(self, output, target, random_loc, s2_est_obMp):\n",
    "        self.loss = 0\n",
    "        out_loss = {}\n",
    "\n",
    "        if self.s2_est_n:\n",
    "            random_x_loc, random_y_loc = random_loc\n",
    "            n_est, n_tar = output['n'], target['n'][:,:,random_x_loc - 8:random_x_loc + 8,random_y_loc - 8:random_y_loc + 8]\n",
    "            n_num = n_tar.nelement() // n_tar.shape[1]\n",
    "            if not hasattr(self, 'n_flag') or n_num != self.n_flag.nelement():\n",
    "                self.n_flag = n_tar.data.new().resize_(n_num).fill_(1)\n",
    "            self.out_reshape = n_est.permute(0, 2, 3, 1).contiguous().view(-1, 3)\n",
    "            self.gt_reshape  = n_tar.permute(0, 2, 3, 1).contiguous().view(-1, 3)\n",
    "            normal_loss = self.n_crit(self.out_reshape, self.gt_reshape, self.n_flag)\n",
    "            normal_loss = torch.acos(1 - normal_loss) / 3.14159 * 180\n",
    "            self.loss += self.normal_w * normal_loss \n",
    "            out_loss['N_loss'] = normal_loss.item() \n",
    "        if s2_est_obMp:\n",
    "            ob_map_est, ob_map_tar = output['ob_map_dense'], target['ob_map_real']\n",
    "\n",
    "            ob_map_mask = torch.gt(ob_map_tar,0)\n",
    "            ob_map_est = ob_map_est * ob_map_mask\n",
    "\n",
    "            rec_loss = self.rec_crit(ob_map_est, ob_map_tar)\n",
    "            self.loss += self.rec_w * rec_loss\n",
    "            out_loss['Rec_loss'] = rec_loss.item()\n",
    "        return out_loss\n",
    "\n",
    "    def backward(self):\n",
    "        self.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Records(object):\n",
    "    \"\"\"\n",
    "    Records->Train,Val->Loss,Accuracy->Epoch1,2,3->[v1,v2]\n",
    "    IterRecords->Train,Val->Loss, Accuracy,->[v1,v2]\n",
    "    \"\"\"\n",
    "    def __init__(self, log_dir, records=None):\n",
    "        if records == None:\n",
    "            self.records = OrderedDict()\n",
    "        else:\n",
    "            self.records = records\n",
    "        self.iter_rec = OrderedDict()\n",
    "        self.log_dir  = log_dir\n",
    "        self.classes = ['loss', 'acc', 'err', 'ratio']\n",
    "\n",
    "    def resetIter(self):\n",
    "        self.iter_rec.clear()\n",
    "\n",
    "    def checkDict(self, a_dict, key, sub_type='dict'):\n",
    "        if key not in a_dict.keys():\n",
    "            if sub_type == 'dict':\n",
    "                a_dict[key] = OrderedDict()\n",
    "            if sub_type == 'list':\n",
    "                a_dict[key] = []\n",
    "\n",
    "    def updateIter(self, split, keys, values):\n",
    "        self.checkDict(self.iter_rec, split, 'dict')\n",
    "        for k, v in zip(keys, values):\n",
    "            self.checkDict(self.iter_rec[split], k, 'list')\n",
    "            self.iter_rec[split][k].append(v)\n",
    "\n",
    "    def saveIterRecord(self, epoch, reset=True):\n",
    "        for s in self.iter_rec.keys(): # s stands for split\n",
    "            self.checkDict(self.records, s, 'dict')\n",
    "            for k in self.iter_rec[s].keys():\n",
    "                self.checkDict(self.records[s], k, 'dict')\n",
    "                self.checkDict(self.records[s][k], epoch, 'list')\n",
    "                self.records[s][k][epoch].append(np.mean(self.iter_rec[s][k]))\n",
    "        if reset: \n",
    "            self.resetIter()\n",
    "\n",
    "    def insertRecord(self, split, key, epoch, value):\n",
    "        self.checkDict(self.records, split, 'dict')\n",
    "        self.checkDict(self.records[split], key, 'dict')\n",
    "        self.checkDict(self.records[split][key], epoch, 'list')\n",
    "        self.records[split][key][epoch].append(value)\n",
    "\n",
    "    def iterRecToString(self, split, epoch):\n",
    "        rec_strs = ''\n",
    "        for c in self.classes:\n",
    "            strs = ''\n",
    "            for k in self.iter_rec[split].keys():\n",
    "                if (c in k.lower()):\n",
    "                    strs += '{}: {:.3f}| '.format(k, np.mean(self.iter_rec[split][k]))\n",
    "            if strs != '':\n",
    "                rec_strs += '\\t [{}] {}\\n'.format(c.upper(), strs)\n",
    "        self.saveIterRecord(epoch)\n",
    "        return rec_strs\n",
    "\n",
    "    def epochRecToString(self, split, epoch):\n",
    "        rec_strs = ''\n",
    "        for c in self.classes:\n",
    "            strs = ''\n",
    "            for k in self.records[split].keys():\n",
    "                if (c in k.lower()) and (epoch in self.records[split][k].keys()):\n",
    "                    strs += '{}: {:.3f}| '.format(k, np.mean(self.records[split][k][epoch]))\n",
    "            if strs != '':\n",
    "                rec_strs += '\\t [{}] {}\\n'.format(c.upper(), strs)\n",
    "        return rec_strs\n",
    "\n",
    "    def recordToDictOfArray(self, splits, epoch=-1, intv=1):\n",
    "        if len(self.records) == 0: return {}\n",
    "        if type(splits) == str: splits = [splits]\n",
    "\n",
    "        dict_of_array = OrderedDict()\n",
    "        for split in splits:\n",
    "            for k in self.records[split].keys():\n",
    "                y_array, x_array = [], []\n",
    "                if epoch < 0:\n",
    "                    for ep in self.records[split][k].keys():\n",
    "                        y_array.append(np.mean(self.records[split][k][ep]))\n",
    "                        x_array.append(ep)\n",
    "                else:\n",
    "                    if epoch in self.records[split][k].keys():\n",
    "                        y_array = np.array(self.records[split][k][epoch])\n",
    "                        x_array = np.linspace(intv, intv*len(y_array), len(y_array))\n",
    "                dict_of_array[split[0] + split[-1] + '_' + k]      = y_array\n",
    "                dict_of_array[split[0] + split[-1] + '_' + k+'_x'] = x_array\n",
    "        return dict_of_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'log_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d998b39a9228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStage2Crit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrecorder\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mrecorders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'log_dir'"
     ]
    }
   ],
   "source": [
    "optimizers = [optimizer, -1]\n",
    "criterion = Stage2Crit(args)\n",
    "recorder  = recorders.Records(args.log_dir, records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customDataloader(args):\n",
    "#     args.log.printWrite(\"=> fetching img pairs in %s\" % (args.data_dir))\n",
    "    datasets = __import__('datasets.' + args.dataset)\n",
    "    dataset_file = getattr(datasets, args.dataset)\n",
    "    train_set = getattr(dataset_file, args.dataset)(args, args.data_dir, 'train')\n",
    "    val_set   = getattr(dataset_file, args.dataset)(args, args.data_dir, 'val')\n",
    "\n",
    "    if args.concat_data:\n",
    "#         args.log.printWrite('****** Using cocnat data ******')\n",
    "#         args.log.printWrite(\"=> fetching img pairs in '{}'\".format(args.data_dir2))\n",
    "        train_set2 = getattr(dataset_file, args.dataset)(args, args.data_dir2, 'train')\n",
    "        val_set2   = getattr(dataset_file, args.dataset)(args, args.data_dir2, 'val')\n",
    "        train_set  = torch.utils.data.ConcatDataset([train_set, train_set2])\n",
    "        val_set    = torch.utils.data.ConcatDataset([val_set,   val_set2])\n",
    "\n",
    "#     args.log.printWrite('Found Data:\\t %d Train and %d Val' % (len(train_set), len(val_set)))\n",
    "#     args.log.printWrite('\\t Train Batch: %d, Val Batch: %d' % (args.batch, args.val_batch))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch,\n",
    "        num_workers=args.workers, pin_memory=args.cuda, shuffle=True)\n",
    "    test_loader  = torch.utils.data.DataLoader(val_set , batch_size=args.val_batch,\n",
    "        num_workers=args.workers, pin_memory=args.cuda, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = customDataloader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[1].train()\n",
    "models[0].eval()\n",
    "optimizer, optimizer_c = optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model_utils.parseData(args, sample,None, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = model_utils.getInput(args, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_c = models[0](input); \n",
    "input.append(pred_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0412e-42, 5.8342e-37, 1.9666e-31, 4.7624e-25, 4.1670e-19,\n",
       "        2.5075e-13, 1.9390e-08, 1.2796e-04, 1.3743e-01, 8.4075e-01, 2.1676e-02,\n",
       "        1.2641e-05, 1.5157e-10, 4.3395e-15, 2.7454e-20, 8.4375e-26, 1.9152e-30,\n",
       "        9.0211e-34, 1.5246e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00], device='cuda:0')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(pred_c['dirs_x'][1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 512, 512])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "s2_est_obMp = True\n",
    "if s2_est_obMp:\n",
    "    start_loc, end_loc = 20, 108\n",
    "    random_loc = torch.randint(start_loc,end_loc,[2,1])\n",
    "    input.append(random_loc)\n",
    "    # print (random_loc)\n",
    "    data['ob_map_real'] = model_utils.parseData_stage2(args, sample, random_loc, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_all = sample['img_all']\n",
    "if args.in_light:\n",
    "    dirs = sample['dirs_all'].expand_as(img)\n",
    "else: # predict lighting, prepare ground truth\n",
    "    n, c, h, w = sample['dirs_all'].shape\n",
    "    dirs_split = torch.split(sample['dirs_all'].view(n, c), 3, 1)\n",
    "\n",
    "x_loc, y_loc = random_loc\n",
    "img_all_crop = img_all[:,:,x_loc - 8:x_loc + 8, y_loc - 8:y_loc + 8]\n",
    "del img_all\n",
    "if args.cuda:\n",
    "    img_all_crop = img_all_crop.cuda()\n",
    "n, c, h, w = img_all_crop.shape\n",
    "imgs = list(torch.split(img_all_crop, 3, 1))\n",
    "for i in range(len(imgs)):\n",
    "    img_patch = imgs[i].mean(1)\n",
    "    img_patch = img_patch.repeat_interleave(32,1).repeat_interleave(32,2)\n",
    "    dirs = dirs_split[i]\n",
    "    if args.cuda:\n",
    "        dirs = dirs.cuda()\n",
    "    x= 0.5*(dirs[:,0]+1)*(32-1); \n",
    "    x=torch.round(x).type(torch.uint8).unsqueeze(1);\n",
    "    x_one_hot = torch.zeros(n, 32).cuda().scatter_(1, x.long(), 1).unsqueeze(2).repeat(1,1,32)\n",
    "    y= 0.5*(dirs[:,1]+1)*(32-1);\n",
    "    y=torch.round(y).type(torch.uint8).unsqueeze(1);\n",
    "    y_one_hot = torch.zeros(n, 32).cuda().scatter_(1, y.long(), 1).unsqueeze(1).repeat(1,32,1)\n",
    "    loc_one_hot = x_one_hot * y_one_hot\n",
    "    loc_one_hot = loc_one_hot.repeat(1,16,16)\n",
    "    if i == 0:\n",
    "        ob_map_real = img_patch * loc_one_hot\n",
    "    else:\n",
    "        ob_map_real,_ = torch.stack([ob_map_real, img_patch * loc_one_hot],1).max(1)\n",
    "ob_map_real = ob_map_real.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_one_hot[1,:,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dirs.cuda()\n",
    "x= 0.5*(dirs[:,0]+1)*(32-1); \n",
    "x=torch.round(x).type(torch.uint8).unsqueeze(1);\n",
    "x_one_hot = torch.zeros(n, 32).cuda().scatter_(1, x.long(), 1).unsqueeze(2).repeat(1,1,32)\n",
    "y= 0.5*(dirs[:,1]+1)*(32-1);\n",
    "y=torch.round(y).type(torch.uint8).unsqueeze(1);\n",
    "y_one_hot = torch.zeros(n, 32).cuda().scatter_(1, y.long(), 1).unsqueeze(1).repeat(1,32,1)\n",
    "loc_one_hot = x_one_hot * y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-63f558fe5494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloc_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "loc_one_hot.shape[0,0:32,0:32].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 0.5*(dirs[:,0]+1)*(32-1); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dirs_split[i]\n",
    "img_patch = imgs[i].mean(1)\n",
    "img_patch = img_patch.repeat_interleave(32,1).repeat_interleave(32,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_all_crop.max().max().max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_patch = imgs[i].mean(1)\n",
    "img_patch = img_patch.repeat_interleave(32,1).repeat_interleave(32,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8220, device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[996].max().max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27],\n",
       "        [25],\n",
       "        [ 7],\n",
       "        [20],\n",
       "        [ 1],\n",
       "        [ 5],\n",
       "        [12],\n",
       "        [24]], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_one_hot = x_one_hot * y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 32])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32., device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_one_hot[0,:32,:32].sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 32])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_one_hot[0,:32,:32].sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2276, 0.2436, 0.2650, 0.2624, 0.4042, 0.4872, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2383, 0.2597, 0.2757, 0.3025, 0.4444, 0.4685, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2383, 0.2543, 0.2757, 0.3025, 0.4605, 0.4765, 0.5220, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2329, 0.2490, 0.2650, 0.3641, 0.4471, 0.4846, 0.5220, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0959, 0.0148, 0.0553, 0.0443, 0.0037, 0.0111, 0.0148, 0.0037,\n",
       "          0.0074, 0.0295, 0.0258, 0.0443, 0.0295, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0332, 0.0332, 0.0184, 0.0258, 0.0295, 0.0221, 0.0074, 0.0074,\n",
       "          0.0074, 0.0221, 0.0111, 0.0037, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0258, 0.0221, 0.0111, 0.0111, 0.0000, 0.0037, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0184, 0.0111, 0.0111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0279, 0.0390, 0.0195, 0.2371, 0.1785, 0.1729, 0.1422, 0.1869,\n",
       "          0.1060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0335, 0.0335, 0.0307, 0.2901, 0.2594, 0.4267, 0.3012, 0.1757,\n",
       "          0.0948, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0167, 0.0279, 0.0251, 0.3207, 0.4351, 0.2845, 0.2761, 0.1590,\n",
       "          0.1060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0139, 0.0195, 0.3514, 0.4351, 1.1575, 0.2956, 0.2427, 0.1701,\n",
       "          0.1116, 0.0139, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.1613, 0.2729, 0.2531, 0.1166, 0.0546, 0.1216, 0.1588, 0.1811,\n",
       "          0.1315, 0.1141, 0.1092, 0.0868, 0.0720, 0.1390, 0.1067, 0.5186],\n",
       "         [0.1712, 0.2208, 0.2953, 0.4566, 0.4367, 0.1613, 0.1687, 0.1663,\n",
       "          0.1911, 0.2729, 0.2754, 0.1563, 0.0397, 0.0769, 0.1092, 0.2854],\n",
       "         [0.1613, 0.1811, 0.2729, 0.6352, 0.4417, 0.3970, 0.3524, 0.2382,\n",
       "          0.2457, 0.2829, 0.3697, 0.5385, 0.4516, 0.1563, 0.1191, 0.0670],\n",
       "         [0.1737, 0.2357, 0.3722, 0.5558, 0.5533, 0.4045, 0.3449, 0.3995,\n",
       "          0.3896, 0.2506, 0.2878, 0.3623, 0.5806, 0.4392, 0.0571, 0.1390]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_patch[:4,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data['ob_map_real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2972, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,0,,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=10\n",
    "j=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3077, 0.3027, 0.2928, 0.2804, 0.0000, 0.2457, 0.2357, 0.2283],\n",
       "        [0.0000, 0.0000, 0.0000, 0.2779, 0.2655, 0.2506, 0.0000, 0.2208],\n",
       "        [0.3127, 0.3002, 0.2878, 0.2729, 0.2655, 0.2531, 0.2432, 0.2208],\n",
       "        [0.3102, 0.3027, 0.2878, 0.2754, 0.2680, 0.2556, 0.2382, 0.2258],\n",
       "        [0.3077, 0.3002, 0.2804, 0.2779, 0.2655, 0.2531, 0.2382, 0.2208],\n",
       "        [0.0000, 0.2953, 0.2854, 0.2705, 0.2605, 0.2432, 0.2332, 0.0000],\n",
       "        [0.0000, 0.2878, 0.2754, 0.2655, 0.2556, 0.2382, 0.2258, 0.2159],\n",
       "        [0.2953, 0.2829, 0.2655, 0.2655, 0.2506, 0.2382, 0.2159, 0.2035]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3,0,32*i+12:32*(i+1)-12,32*j+12:32*(j+1)-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1227515, device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(sum(a==0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3000, 16, 16])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_all_crop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2078078, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(sum(img_all_crop==0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f0a2f8213675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "b = torch.ones(100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',np.mat(a[1,0,:,:].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8220, device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max().max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.split(x[0], 3, 1)\n",
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_x = torch.split(x[idx]['dirs_x'], x[0].shape[0], 0)\n",
    "dirs_y = torch.split(x[idx]['dirs_y'], x[0].shape[0], 0)\n",
    "dirs = torch.split(x[idx]['dirs'], x[0].shape[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_x_loc, random_y_loc = x[idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([57])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_x_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([60])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_y_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_map = nn.functional.softmax(dirs_x[i],1).unsqueeze(2).repeat(1,1,dirs_x[i].shape[1]) * nn.functional.softmax(dirs_y[i],1).unsqueeze(1).repeat(1,dirs_y[i].shape[1],1)\n",
    "dirs_map = dirs_map.repeat(1,16,16).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 512, 512])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[i][:,:,random_x_loc - 8:random_x_loc + 8,random_y_loc - 8:random_y_loc + 8]\n",
    "img = img.repeat_interleave(32,2).repeat_interleave(32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0824, 0.0824, 0.0824,  ..., 0.0824, 0.0824, 0.0824],\n",
       "        [0.0824, 0.0824, 0.0824,  ..., 0.0824, 0.0824, 0.0824],\n",
       "        [0.0824, 0.0824, 0.0824,  ..., 0.0824, 0.0824, 0.0824],\n",
       "        ...,\n",
       "        [0.0824, 0.0824, 0.0824,  ..., 0.0824, 0.0824, 0.0824],\n",
       "        [0.0824, 0.0824, 0.0824,  ..., 0.0824, 0.0824, 0.0824],\n",
       "        [0.0824, 0.0824, 0.0824,  ..., 0.0824, 0.0824, 0.0824]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[1,1,0:32,0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_idx = dirs_x[i].data.max(1)\n",
    "_, y_idx = dirs_y[i].data.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,_ = dirs_map[0,0,0:32,0:32].max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor(0.3065, device='cuda:0'),\n",
       "indices=tensor(6, device='cuda:0'))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 18, 10, 22, 14,  7, 10, 27], device='cuda:0')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15, 22, 13, 28, 29,  4, 16, 21], device='cuda:0')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 512, 512])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x_idx.type(torch.uint8).unsqueeze(1);\n",
    "x_one_hot = torch.zeros(n, 32).cuda().scatter_(1, x.long(), 1).unsqueeze(2).repeat(1,1,32)\n",
    "y=y_idx.type(torch.uint8).unsqueeze(1);\n",
    "y_one_hot = torch.zeros(n, 32).cuda().scatter_(1, y.long(), 1).unsqueeze(1).repeat(1,32,1)\n",
    "loc_one_hot = x_one_hot * y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 32])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0784],\n",
       "        [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0784],\n",
       "        [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0784],\n",
       "        ...,\n",
       "        [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0784],\n",
       "        [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0784],\n",
       "        [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0784]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray[0,0:32,0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_filter = torch.zeros(32,32)\n",
    "max_filter[x_idx,y_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_filter.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6275, device='cuda:0')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_filtered[0,0:32,0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 128])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[i].mean(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_idx = dirs_x[i].data.max(1)\n",
    "_, y_idx = dirs_y[i].data.max(1)\n",
    "x=x_idx.type(torch.uint8).unsqueeze(1);\n",
    "x_one_hot = torch.zeros(n, 32).cuda().scatter_(1, x.long(), 1).unsqueeze(2).repeat(1,1,32)\n",
    "y=y_idx.type(torch.uint8).unsqueeze(1);\n",
    "y_one_hot = torch.zeros(n, 32).cuda().scatter_(1, y.long(), 1).unsqueeze(1).repeat(1,32,1)\n",
    "loc_one_hot = x_one_hot * y_one_hot\n",
    "max_filter = loc_one_hot.repeat(1,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_filter[0,6,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_x = torch.split(x[idx]['dirs_x'], x[0].shape[0], 0)\n",
    "dirs_y = torch.split(x[idx]['dirs_y'], x[0].shape[0], 0)\n",
    "dirs = torch.split(x[idx]['dirs'], x[0].shape[0], 0)\n",
    "random_x_loc, random_y_loc = x[idx + 1]\n",
    "s2_inputs = []\n",
    "tmp = []\n",
    "for i in range(len(imgs)):\n",
    "    n, c, h, w = imgs[i].shape\n",
    "    dirs_map = nn.functional.softmax(dirs_x[i],1).unsqueeze(2).repeat(1,1,dirs_x[i].shape[1]) * nn.functional.softmax(dirs_y[i],1).unsqueeze(1).repeat(1,dirs_y[i].shape[1],1)\n",
    "    dirs_map = dirs_map.repeat(1,16,16).unsqueeze(1)\n",
    "    dirs_map = dirs_map.cuda()\n",
    "    # l_dir = dirs[i] if dirs[i].dim() == 4 else dirs[i].view(n, -1, 1, 1)\n",
    "    # l_int = torch.diag(1.0 / (ints[i].contiguous().view(-1)+1e-8))\n",
    "    # img   = imgs[i].contiguous().view(n * c, h * w)\n",
    "    # img   = torch.mm(l_int, img).view(n, c, h, w)\n",
    "    img = imgs[i][:,:,random_x_loc - 8:random_x_loc + 8,random_y_loc - 8:random_y_loc + 8]\n",
    "    img = img.repeat_interleave(32,2).repeat_interleave(32,3)\n",
    "    # img = img.mean(1)\n",
    "    # img = img.unsqueeze(1)\n",
    "    img_light = torch.cat([img, dirs_map], 1)\n",
    "    s2_inputs.append(img_light)\n",
    "\n",
    "    _, x_idx = dirs_x[i].data.max(1)\n",
    "    _, y_idx = dirs_y[i].data.max(1)\n",
    "    x=x_idx.type(torch.uint8).unsqueeze(1);\n",
    "    x_one_hot = torch.zeros(n, 32).cuda().scatter_(1, x.long(), 1).unsqueeze(2).repeat(1,1,32)\n",
    "    y=y_idx.type(torch.uint8).unsqueeze(1);\n",
    "    y_one_hot = torch.zeros(n, 32).cuda().scatter_(1, y.long(), 1).unsqueeze(1).repeat(1,32,1)\n",
    "    loc_one_hot = x_one_hot * y_one_hot\n",
    "    max_filter = loc_one_hot.repeat(1,16,16)\n",
    "    max_filter = max_filter.cuda()\n",
    "    img_gray = img.mean(1)\n",
    "    img_gray_filtered = img_gray * max_filter\n",
    "    tmp.append(img_gray_filtered)\n",
    "regressor_inputs,_ = torch.stack(tmp,1).max(1)\n",
    "regressor_inputs = regressor_inputs.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter2 = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(data_iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model_utils.parseData(args, sample, None, 'val')\n",
    "input = model_utils.getInput(args, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c = models[0](input);\n",
    "input.append(pred_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_est_obMp = True\n",
    "if s2_est_obMp:\n",
    "    start_loc, end_loc = 20, 108\n",
    "    random_loc = torch.randint(start_loc,end_loc,[2,1])\n",
    "    input.append(random_loc)\n",
    "    data['ob_map_real'] = model_utils.parseData_stage2(args, sample, random_loc, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = models[1](input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ob_map_dense': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0',\n",
       "        grad_fn=<IndexPutBackward>),\n",
       " 'n': tensor([[[[ 0.3467,  0.1389,  0.0499,  0.0376, -0.0399,  0.0072,  0.0375,\n",
       "             0.0549,  0.0800,  0.0204, -0.0094, -0.0165, -0.0160, -0.0198,\n",
       "            -0.0111,  0.0291],\n",
       "           [ 0.0899,  0.2337,  0.0402, -0.1092, -0.2564, -0.2216, -0.3326,\n",
       "            -0.4097, -0.2549, -0.2658, -0.3584, -0.3657, -0.3777, -0.3904,\n",
       "            -0.3536, -0.2839],\n",
       "           [ 0.1298,  0.5079,  0.3457,  0.0325, -0.2606, -0.3157, -0.3540,\n",
       "            -0.5260, -0.4461, -0.2996, -0.4105, -0.4190, -0.3985, -0.4169,\n",
       "            -0.4052, -0.3512],\n",
       "           [ 0.2383,  0.6385,  0.2333, -0.1055, -0.3842, -0.4986, -0.4190,\n",
       "            -0.5082, -0.4944, -0.3627, -0.4387, -0.4160, -0.3582, -0.4044,\n",
       "            -0.4081, -0.3529],\n",
       "           [ 0.2433,  0.6807,  0.1824, -0.1702, -0.4102, -0.5245, -0.4684,\n",
       "            -0.4899, -0.4835, -0.4202, -0.4599, -0.4150, -0.3426, -0.3379,\n",
       "            -0.3288, -0.3253],\n",
       "           [ 0.2007,  0.5992, -0.0044, -0.2837, -0.5255, -0.5390, -0.4687,\n",
       "            -0.4494, -0.4781, -0.4833, -0.4841, -0.4541, -0.4278, -0.3903,\n",
       "            -0.3918, -0.4218],\n",
       "           [ 0.1267,  0.4295, -0.0826, -0.4416, -0.6021, -0.5646, -0.4724,\n",
       "            -0.3839, -0.4223, -0.4902, -0.4855, -0.4383, -0.4098, -0.3954,\n",
       "            -0.3874, -0.3530],\n",
       "           [ 0.0037,  0.2945,  0.1906, -0.2716, -0.5665, -0.5672, -0.4540,\n",
       "            -0.3674, -0.4162, -0.4664, -0.4895, -0.4941, -0.4397, -0.3674,\n",
       "            -0.2537, -0.2084],\n",
       "           [-0.0130,  0.2284,  0.3244,  0.0824, -0.3287, -0.4484, -0.3927,\n",
       "            -0.3523, -0.4115, -0.4322, -0.4243, -0.4710, -0.5420, -0.5610,\n",
       "            -0.4551, -0.2601],\n",
       "           [ 0.2334,  0.3989,  0.3213,  0.1555, -0.0599, -0.2665, -0.3266,\n",
       "            -0.3070, -0.3219, -0.3198, -0.3110, -0.3797, -0.4732, -0.5432,\n",
       "            -0.4788, -0.3113],\n",
       "           [ 0.1960,  0.3549,  0.3559,  0.2506,  0.1611, -0.1586, -0.2853,\n",
       "            -0.3016, -0.3000, -0.2554, -0.2437, -0.2830, -0.3648, -0.4636,\n",
       "            -0.4435, -0.3389],\n",
       "           [-0.0216,  0.1906,  0.3145,  0.3354,  0.3352,  0.2009,  0.0496,\n",
       "            -0.0449, -0.1506, -0.2100, -0.2236, -0.2088, -0.2454, -0.3283,\n",
       "            -0.3157, -0.3313],\n",
       "           [-0.1347,  0.0822,  0.2089,  0.3416,  0.3934,  0.3430,  0.2425,\n",
       "             0.1796,  0.1020, -0.0280, -0.1638, -0.1828, -0.1523, -0.0866,\n",
       "            -0.0552, -0.2619],\n",
       "           [-0.1398,  0.0545,  0.0991,  0.2505,  0.3327,  0.3315,  0.2856,\n",
       "             0.2607,  0.2634,  0.1945,  0.0477, -0.0116,  0.0292,  0.0545,\n",
       "             0.1070, -0.0087],\n",
       "           [-0.1752, -0.0906, -0.1088,  0.0568,  0.2011,  0.2690,  0.2895,\n",
       "             0.3072,  0.3300,  0.2757,  0.1675,  0.1390,  0.1632,  0.1395,\n",
       "             0.2049,  0.1376],\n",
       "           [-0.0266,  0.0431,  0.0255,  0.1347,  0.2356,  0.2180,  0.2072,\n",
       "             0.2404,  0.2645,  0.2198,  0.1970,  0.2203,  0.2163,  0.2090,\n",
       "             0.2803, -0.0164]],\n",
       " \n",
       "          [[ 0.5534,  0.9432,  0.9641,  0.9665,  0.9490,  0.9362,  0.9427,\n",
       "             0.9325,  0.9067,  0.8820,  0.8747,  0.8693,  0.8687,  0.8686,\n",
       "             0.8711,  0.7720],\n",
       "           [ 0.0229,  0.8372,  0.9777,  0.9716,  0.9018,  0.7636,  0.6263,\n",
       "             0.6403,  0.7152,  0.6600,  0.5713,  0.4941,  0.4589,  0.4536,\n",
       "             0.4929,  0.3290],\n",
       "           [ 0.0508,  0.6428,  0.9088,  0.9785,  0.8975,  0.6402,  0.4601,\n",
       "             0.4927,  0.6958,  0.7848,  0.6894,  0.5931,  0.4837,  0.4318,\n",
       "             0.4810,  0.3410],\n",
       "           [-0.0174,  0.4733,  0.9251,  0.9783,  0.8717,  0.6261,  0.4803,\n",
       "             0.5318,  0.6720,  0.7756,  0.7267,  0.6703,  0.5821,  0.4694,\n",
       "             0.4877,  0.3500],\n",
       "           [-0.0723,  0.4063,  0.9004,  0.9564,  0.8141,  0.5347,  0.4989,\n",
       "             0.5893,  0.6477,  0.7162,  0.7241,  0.7431,  0.7339,  0.6301,\n",
       "             0.5974,  0.4002],\n",
       "           [-0.0692,  0.4489,  0.9093,  0.9304,  0.6996,  0.4666,  0.5268,\n",
       "             0.5873,  0.6410,  0.7012,  0.7150,  0.7513,  0.7713,  0.6993,\n",
       "             0.7192,  0.4799],\n",
       "           [ 0.0990,  0.5111,  0.8230,  0.8499,  0.5847,  0.4503,  0.5490,\n",
       "             0.5928,  0.6135,  0.6701,  0.6718,  0.6087,  0.6787,  0.7084,\n",
       "             0.7045,  0.4132],\n",
       "           [ 0.2857,  0.6842,  0.7143,  0.8353,  0.7084,  0.5475,  0.5339,\n",
       "             0.5640,  0.5724,  0.6188,  0.6434,  0.5949,  0.6462,  0.7265,\n",
       "             0.5213,  0.2348],\n",
       "           [ 0.4409,  0.7969,  0.7107,  0.7661,  0.8877,  0.7873,  0.6254,\n",
       "             0.6147,  0.6224,  0.6611,  0.7050,  0.7108,  0.6233,  0.5685,\n",
       "             0.4424,  0.1908],\n",
       "           [ 0.5410,  0.7301,  0.7328,  0.8002,  0.9471,  0.9225,  0.8223,\n",
       "             0.7949,  0.8012,  0.8243,  0.8421,  0.8029,  0.6807,  0.5600,\n",
       "             0.4811,  0.1949],\n",
       "           [ 0.7822,  0.8553,  0.8061,  0.8234,  0.8775,  0.8681,  0.8327,\n",
       "             0.8338,  0.8444,  0.8789,  0.9129,  0.9010,  0.8265,  0.6784,\n",
       "             0.5063,  0.2117],\n",
       "           [ 0.8114,  0.9372,  0.8706,  0.7824,  0.7712,  0.8043,  0.8312,\n",
       "             0.8314,  0.7888,  0.8195,  0.8762,  0.8789,  0.8851,  0.8415,\n",
       "             0.7386,  0.3686],\n",
       "           [ 0.5311,  0.8903,  0.8755,  0.7901,  0.7634,  0.7796,  0.7916,\n",
       "             0.7906,  0.7717,  0.7766,  0.8004,  0.8173,  0.8362,  0.8639,\n",
       "             0.8680,  0.5434],\n",
       "           [ 0.3445,  0.8029,  0.8139,  0.7741,  0.7841,  0.7928,  0.7791,\n",
       "             0.7692,  0.7606,  0.7477,  0.7538,  0.7779,  0.7661,  0.7887,\n",
       "             0.8458,  0.6793],\n",
       "           [ 0.1789,  0.7422,  0.8422,  0.8219,  0.8066,  0.8433,  0.8458,\n",
       "             0.8151,  0.7903,  0.7966,  0.8116,  0.8353,  0.8469,  0.8420,\n",
       "             0.7886,  0.6010],\n",
       "           [ 0.1617,  0.6800,  0.8308,  0.8195,  0.7662,  0.8049,  0.8308,\n",
       "             0.8143,  0.8026,  0.8033,  0.7875,  0.7938,  0.7906,  0.7695,\n",
       "             0.7055,  0.6118]],\n",
       " \n",
       "          [[ 0.7573,  0.3017,  0.2607,  0.2537,  0.3127,  0.3515,  0.3316,\n",
       "             0.3569,  0.4142,  0.4708,  0.4845,  0.4939,  0.4952,  0.4951,\n",
       "             0.4910,  0.6350],\n",
       "           [ 0.9957,  0.4946,  0.2063,  0.2098,  0.3480,  0.6065,  0.7051,\n",
       "             0.6497,  0.6508,  0.7027,  0.7384,  0.7888,  0.8042,  0.8011,\n",
       "             0.7950,  0.9006],\n",
       "           [ 0.9902,  0.5735,  0.2336,  0.2038,  0.3557,  0.7004,  0.8142,\n",
       "             0.6932,  0.5628,  0.5426,  0.5969,  0.6875,  0.7793,  0.7998,\n",
       "             0.7775,  0.8720],\n",
       "           [ 0.9710,  0.6069,  0.2995,  0.1783,  0.3043,  0.5994,  0.7706,\n",
       "             0.6774,  0.5513,  0.5166,  0.5286,  0.6146,  0.7300,  0.7849,\n",
       "             0.7718,  0.8677],\n",
       "           [ 0.9672,  0.6095,  0.3950,  0.2375,  0.4109,  0.6626,  0.7291,\n",
       "             0.6424,  0.5888,  0.5573,  0.5140,  0.5250,  0.5866,  0.6991,\n",
       "             0.7315,  0.8568],\n",
       "           [ 0.9772,  0.6629,  0.4161,  0.2323,  0.4842,  0.7013,  0.7091,\n",
       "             0.6731,  0.6004,  0.5242,  0.5044,  0.4789,  0.4714,  0.5989,\n",
       "             0.5738,  0.7693],\n",
       "           [ 0.9870,  0.7445,  0.5620,  0.2875,  0.5437,  0.6917,  0.6895,\n",
       "             0.7080,  0.6673,  0.5574,  0.5594,  0.6613,  0.6095,  0.5847,\n",
       "             0.5946,  0.8394],\n",
       "           [ 0.9583,  0.6672,  0.6734,  0.4780,  0.4210,  0.6152,  0.7133,\n",
       "             0.7395,  0.7065,  0.6321,  0.5886,  0.6340,  0.6238,  0.5807,\n",
       "             0.8148,  0.9494],\n",
       "           [ 0.8975,  0.5592,  0.6243,  0.6374,  0.3223,  0.4231,  0.6743,\n",
       "             0.7057,  0.6658,  0.6133,  0.5683,  0.5224,  0.5637,  0.6017,\n",
       "             0.7728,  0.9465],\n",
       "           [ 0.8080,  0.5549,  0.5998,  0.5792,  0.3152,  0.2791,  0.4660,\n",
       "             0.5233,  0.5045,  0.4671,  0.4406,  0.4595,  0.5593,  0.6256,\n",
       "             0.7344,  0.9301],\n",
       "           [ 0.5914,  0.3775,  0.4729,  0.5091,  0.4518,  0.4704,  0.4746,\n",
       "             0.4624,  0.4438,  0.4028,  0.3274,  0.3288,  0.4287,  0.5699,\n",
       "             0.7396,  0.9167],\n",
       "           [ 0.5841,  0.2921,  0.3783,  0.5248,  0.5411,  0.5593,  0.5538,\n",
       "             0.5539,  0.5958,  0.5332,  0.4270,  0.4288,  0.3955,  0.4290,\n",
       "             0.5957,  0.8686],\n",
       "           [ 0.8365,  0.4480,  0.4358,  0.5090,  0.5123,  0.5241,  0.5608,\n",
       "             0.5854,  0.6278,  0.6293,  0.5767,  0.5464,  0.5269,  0.4961,\n",
       "             0.4934,  0.7976],\n",
       "           [ 0.9283,  0.5936,  0.5725,  0.5814,  0.5239,  0.5114,  0.5580,\n",
       "             0.5835,  0.5933,  0.6349,  0.6553,  0.6282,  0.6421,  0.6123,\n",
       "             0.5226,  0.7338],\n",
       "           [ 0.9682,  0.6641,  0.5281,  0.5668,  0.5559,  0.4652,  0.4481,\n",
       "             0.4911,  0.5163,  0.5380,  0.5596,  0.5319,  0.5060,  0.5212,\n",
       "             0.5798,  0.7873],\n",
       "           [ 0.9865,  0.7319,  0.5560,  0.5571,  0.5978,  0.5519,  0.5165,\n",
       "             0.5283,  0.5347,  0.5535,  0.5839,  0.5668,  0.5729,  0.6034,\n",
       "             0.6509,  0.7909]]]], device='cuda:0', grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eval_utils, time_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_var = data['m']\n",
    "data_batch = args.val_batch if split == 'val' else args.test_batch\n",
    "iter_res = []\n",
    "error = ''\n",
    "# if args.s1_est_d:\n",
    "#     l_acc, data['dir_err'] = eval_utils.calDirsAcc(data['dirs'].data, pred_c['dirs'].data, data_batch)\n",
    "#     recorder.updateIter(split, l_acc.keys(), l_acc.values())\n",
    "#     iter_res.append(l_acc['l_err_mean'])\n",
    "#     error += 'D_%.3f-' % (l_acc['l_err_mean']) \n",
    "# if args.s1_est_i:\n",
    "#     int_acc, data['int_err'] = eval_utils.calIntsAcc(data['ints'].data, pred_c['intens'].data, data_batch)\n",
    "#     recorder.updateIter(split, int_acc.keys(), int_acc.values())\n",
    "#     iter_res.append(int_acc['ints_ratio'])\n",
    "#     error += 'I_%.3f-' % (int_acc['ints_ratio'])\n",
    "if args.s1_est_d:\n",
    "    l_acc, data['dir_err'] = eval_utils.calDirsAcc(data['dirs'].data, pred_c['dirs'].data, data_batch)\n",
    "    iter_res.append(l_acc['l_err_mean'])\n",
    "    error += 'D_%.3f-' % (l_acc['l_err_mean']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1579022060824/work/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "if args.s2_est_n:\n",
    "    random_x_loc, random_y_loc = random_loc\n",
    "    n_tar = data['n'][:,:,random_x_loc - 8:random_x_loc + 8,random_y_loc - 8:random_y_loc + 8]\n",
    "    mask_var = mask_var[:,:,random_x_loc - 8:random_x_loc + 8,random_y_loc - 8:random_y_loc + 8]\n",
    "    acc, error_map = eval_utils.calNormalAcc(n_tar.data, pred['n'].data, mask_var.data)\n",
    "    iter_res.append(acc['n_err_mean'])\n",
    "    error += 'N_%.3f-' % (acc['n_err_mean'])\n",
    "    data['error_map'] = error_map['angular_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_err_mean': 57.3135986328125,\n",
       " 'n_acc_11': 0.00913241971284151,\n",
       " 'n_acc_30': 0.09132420271635056,\n",
       " 'n_acc_45': 0.2009132355451584}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = (gt_n * pred_n).sum(1).clamp(-1,1)\n",
    "error_map   = torch.acos(dot_product) # [-pi, pi]\n",
    "angular_map = error_map * 180.0 / math.pi\n",
    "angular_map = angular_map * mask.narrow(1, 0, 1).squeeze(1)\n",
    "\n",
    "valid = mask.narrow(1, 0, 1).sum()\n",
    "ang_valid  = angular_map[mask.narrow(1, 0, 1).squeeze(1).byte()]\n",
    "n_err_mean = ang_valid.sum() / valid\n",
    "n_err_med  = ang_valid.median()\n",
    "n_acc_11   = (ang_valid < 11.25).sum().float() / valid\n",
    "n_acc_30   = (ang_valid < 30).sum().float() / valid\n",
    "n_acc_45   = (ang_valid < 45).sum().float() / valid\n",
    "\n",
    "angular_map = colorMap(angular_map.cpu().squeeze(1))\n",
    "value = {'n_err_mean': n_err_mean.item(), \n",
    "        'n_acc_11': n_acc_11.item(), 'n_acc_30': n_acc_30.item(), 'n_acc_45': n_acc_45.item()}\n",
    "angular_error_map = {'angular_map': angular_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros(1,1,16,16)\n",
    "# mask[0,0,1,1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_n = torch.rand(1,1,16,16)\n",
    "pred_n = torch.rand(1,1,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = (gt_n * pred_n).sum(1).clamp(-1,1)\n",
    "error_map   = torch.acos(dot_product) # [-pi, pi]\n",
    "angular_map = error_map * 180.0 / math.pi\n",
    "angular_map = angular_map * mask.narrow(1, 0, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1579022060824/work/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "valid = mask.narrow(1, 0, 1).sum()\n",
    "ang_valid  = angular_map[mask.narrow(1, 0, 1).squeeze(1).byte()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ang_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_err_mean = ang_valid.sum() / valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_err_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-1116b27807d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_err_med\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mang_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "n_err_med  = ang_valid.median() if valid else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_err_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 16, 16])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.narrow(1, 0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(84.9280)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_err_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_acc_11   = (ang_valid < 11.25).sum().float() / valid\n",
    "n_acc_30   = (ang_valid < 30).sum().float() / valid\n",
    "n_acc_45   = (ang_valid < 45).sum().float() / valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_acc_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorMap(diff):\n",
    "    thres = 90\n",
    "    diff_norm = np.clip(diff, 0, thres) / thres\n",
    "    diff_cm = torch.from_numpy(cm.jet(diff_norm.numpy()))[:,:,:, :3]\n",
    "    return diff_cm.permute(0,3,1,2).clone().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "angular_map = colorMap(angular_map.cpu().squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = {'n_err_mean': n_err_mean.item(), \n",
    "            'n_acc_11': n_acc_11.item(), 'n_acc_30': n_acc_30.item(), 'n_acc_45': n_acc_45.item()}\n",
    "angular_error_map = {'angular_map': angular_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_map = angular_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ang_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_acc_11 +1 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData_stage2(args, sample, random_loc, split='train'):\n",
    "    img_all = sample['img_all']\n",
    "    if args.in_light:\n",
    "        dirs = sample['dirs_all'].expand_as(img)\n",
    "    else: # predict lighting, prepare ground truth\n",
    "        n, c, h, w = sample['dirs_all'].shape\n",
    "        dirs_split = torch.split(sample['dirs_all'].view(n, c), 3, 1)\n",
    "    \n",
    "    x_loc, y_loc = random_loc\n",
    "    img_all_crop = img_all[:,:,x_loc - 8:x_loc + 8, y_loc - 8:y_loc + 8]\n",
    "    del img_all\n",
    "    if args.cuda:\n",
    "        img_all_crop = img_all_crop.cuda()\n",
    "    # img_all_crop = img_all_crop.repeat_interleave(32,2).repeat_interleave(32,3)\n",
    "    n, c, h, w = img_all_crop.shape\n",
    "    imgs = list(torch.split(img_all_crop, 3, 1))\n",
    "    # ob_map_real = torch.zeros(n, 512, 512).cuda()\n",
    "    for i in range(len(imgs)):\n",
    "        img_patch = imgs[i].mean(1)\n",
    "        img_patch = img_patch.repeat_interleave(32,1).repeat_interleave(32,2)\n",
    "        dirs = dirs_split[i]\n",
    "        if args.cuda:\n",
    "            dirs = dirs.cuda()\n",
    "        x= 0.5*(dirs[:,0]+1)*(32-1); \n",
    "        x=torch.round(x).type(torch.uint8).unsqueeze(1);\n",
    "        x_one_hot = torch.zeros(n, 32).cuda().scatter_(1, x.long(), 1).unsqueeze(2).repeat(1,1,32)\n",
    "        y= 0.5*(dirs[:,1]+1)*(32-1);\n",
    "        y=torch.round(y).type(torch.uint8).unsqueeze(1);\n",
    "        y_one_hot = torch.zeros(n, 32).cuda().scatter_(1, y.long(), 1).unsqueeze(1).repeat(1,32,1)\n",
    "        loc_one_hot = x_one_hot * y_one_hot\n",
    "        loc_one_hot = loc_one_hot.repeat(1,16,16)\n",
    "        if i == 0:\n",
    "            ob_map_real = img_patch * loc_one_hot\n",
    "        else:\n",
    "            ob_map_real,_ = torch.stack([ob_map_real, img_patch * loc_one_hot],1).max(1)\n",
    "        # ob_map.append(img_patch * loc_one_hot)\n",
    "        # for j in range(n):\n",
    "        #     x= 0.5*(dirs[j,0]+1)*(32-1); \n",
    "        #     x=torch.round(x).type(torch.uint8);\n",
    "        #     y= 0.5*(dirs[j,1]+1)*(32-1);\n",
    "        #     y=torch.round(y).type(torch.uint8);\n",
    "        #     for k in range(16):\n",
    "        #         for l in range(16):\n",
    "        #             ob_map_real[j,x + 32 * k, y + 32 * l] = img_patch[j,k,l]\n",
    "    # ob_map_real = torch.stack(ob_map,1).sum(1)\n",
    "    ob_map_real = ob_map_real.unsqueeze(1)\n",
    "    # print (ob_map_real.shape)\n",
    "    # print (ob_map_real.squeeze()[0,0:32,0:32])\n",
    "    # if args.cuda:\n",
    "    #     ob_map_real = ob_map_real.cuda() \n",
    "    return ob_map_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['dir_x'] = self.dir_x_est(out).squeeze(2).squeeze(2)\n",
    "            outputs['dir_y'] = self.dir_y_est(out).squeeze(2).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInputs(self, x):\n",
    "    imgs = torch.split(x[0], 3, 1)\n",
    "    idx = 1\n",
    "    if self.other['in_light']: idx += 1\n",
    "    if self.other['in_mask']:  idx += 1\n",
    "    dirs_x = torch.split(x[idx]['dirs_x'], x[0].shape[0], 0)\n",
    "    dirs_y = torch.split(x[idx]['dirs_y'], x[0].shape[0], 0)\n",
    "    dirs = torch.split(x[idx]['dirs'], x[0].shape[0], 0)\n",
    "    # ints = torch.split(x[idx]['intens'], 3, 1)\n",
    "    random_x_loc, random_y_loc = x[idx + 1]\n",
    "    # s2_inputs = []\n",
    "    # for i in range(len(imgs)):\n",
    "    #     n, c, h, w = imgs[i].shape\n",
    "    #     l_dir = dirs[i] if dirs[i].dim() == 4 else dirs[i].view(n, -1, 1, 1)\n",
    "    #     # l_int = torch.diag(1.0 / (ints[i].contiguous().view(-1)+1e-8))\n",
    "    #     # img   = imgs[i].contiguous().view(n * c, h * w)\n",
    "    #     # img   = torch.mm(l_int, img).view(n, c, h, w)\n",
    "    #     img_light = torch.cat([img, l_dir.expand_as(img)], 1)\n",
    "    #     s2_inputs.append(img_light)\n",
    "    # return s2_inputs\n",
    "    s2_inputs = []\n",
    "    tmp = []\n",
    "    for i in range(len(imgs)):\n",
    "        n, c, h, w = imgs[i].shape\n",
    "        dirs_map = nn.functional.softmax(dirs_x[i],1).unsqueeze(2).repeat(1,1,dirs_x[i].shape[1]) * nn.functional.softmax(dirs_y[i],1).unsqueeze(1).repeat(1,dirs_y[i].shape[1],1)\n",
    "        dirs_map = dirs_map.repeat(1,16,16).unsqueeze(1)\n",
    "        dirs_map = dirs_map.cuda()\n",
    "        # l_dir = dirs[i] if dirs[i].dim() == 4 else dirs[i].view(n, -1, 1, 1)\n",
    "        # l_int = torch.diag(1.0 / (ints[i].contiguous().view(-1)+1e-8))\n",
    "        # img   = imgs[i].contiguous().view(n * c, h * w)\n",
    "        # img   = torch.mm(l_int, img).view(n, c, h, w)\n",
    "        img = imgs[i][:,:,random_x_loc - 8:random_x_loc + 8,random_y_loc - 8:random_y_loc + 8]\n",
    "        img = img.repeat_interleave(32,2).repeat_interleave(32,3)\n",
    "        # img = img.mean(1)\n",
    "        # img = img.unsqueeze(1)\n",
    "        img_light = torch.cat([img, dirs_map], 1)\n",
    "        s2_inputs.append(img_light)\n",
    "\n",
    "        _, x_idx = dirs_x[i].data.max(1)\n",
    "        _, y_idx = dirs_y[i].data.max(1)\n",
    "        x=x_idx.type(torch.uint8).unsqueeze(1);\n",
    "        x_one_hot = torch.zeros(n, 32).cuda().scatter_(1, x.long(), 1).unsqueeze(2).repeat(1,1,32)\n",
    "        y=y_idx.type(torch.uint8).unsqueeze(1);\n",
    "        y_one_hot = torch.zeros(n, 32).cuda().scatter_(1, y.long(), 1).unsqueeze(1).repeat(1,32,1)\n",
    "        loc_one_hot = x_one_hot * y_one_hot\n",
    "        max_filter = loc_one_hot.repeat(1,16,16)\n",
    "        max_filter = max_filter.cuda()\n",
    "        img_gray = img.mean(1)\n",
    "        img_gray_filtered = img_gray * max_filter\n",
    "        tmp.append(img_gray_filtered)\n",
    "    regressor_inputs,_ = torch.stack(tmp,1).max(1)\n",
    "    regressor_inputs = regressor_inputs.unsqueeze(1)\n",
    "    return s2_inputs, regressor_inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
